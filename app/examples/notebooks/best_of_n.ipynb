{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WQpNapZNWuXP"
   },
   "source": [
    "\n",
    "**Best-of-n sampling as an alternative to RLHF**\n",
    "\n",
    "This notebook compares reward-model scores of prompt based responses from \n",
    "1. a base model (`gpt2-imdb`)\n",
    "2. `RLHF` tuned model based on this base-model \n",
    "3. the base-model again from which we sample n responses to each prompt, score them and take the best scored one AKA the `best-of-n sampled` model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lo98lkdP66_x"
   },
   "source": [
    "Import dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "M1s_iNm773hM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qcdong/anaconda3/envs/handbook/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import pipeline, AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from trl import AutoModelForCausalLMWithValueHead\n",
    "from trl.core import LengthSampler\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7hyrIrO8tcY"
   },
   "source": [
    "Various constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MqS3OM6Q8x6g"
   },
   "outputs": [],
   "source": [
    "root = '/mnt/nas1/models/'\n",
    "ref_model_name = root + \"lvwerra/gpt2-imdb\"\n",
    "model_name = root + \"lvwerra/gpt2-imdb-pos-v2\"\n",
    "reward_model = root + \"lvwerra/distilbert-imdb\"\n",
    "\n",
    "N_BEST_OF = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1YcXeElg6or"
   },
   "source": [
    "Models and  tokenizers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "b855NrL181Hh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qcdong/anaconda3/envs/handbook/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AutoModelForCausalLMWithValueHead(\n",
       "  (pretrained_model): GPT2LMHeadModel(\n",
       "    (transformer): GPT2Model(\n",
       "      (wte): Embedding(50257, 768)\n",
       "      (wpe): Embedding(1024, 768)\n",
       "      (drop): Dropout(p=0.1, inplace=False)\n",
       "      (h): ModuleList(\n",
       "        (0-11): 12 x GPT2Block(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): GPT2Attention(\n",
       "            (c_attn): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "            (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): GPT2MLP(\n",
       "            (c_fc): Conv1D()\n",
       "            (c_proj): Conv1D()\n",
       "            (act): NewGELUActivation()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       "  )\n",
       "  (v_head): ValueHead(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (summary): Linear(in_features=768, out_features=1, bias=True)\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForCausalLMWithValueHead.from_pretrained(model_name)\n",
    "\n",
    "ref_model = AutoModelForCausalLMWithValueHead.from_pretrained(ref_model_name)\n",
    "\n",
    "reward_pipe = pipeline(\"sentiment-analysis\", model=reward_model, device=device)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(ref_model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# cuda-ize models\n",
    "model.cuda()\n",
    "ref_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15496, 995, 0]\n",
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"Hello world!\"))\n",
    "print(tokenizer.decode([15496, 995, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1Cz0gCFhZYJ"
   },
   "source": [
    "Dataset building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LqLVEp5p_8XM"
   },
   "outputs": [],
   "source": [
    "def build_dataset(tokenizer, dataset_name=\"imdb\", input_min_text_length=2, input_max_text_length=8):\n",
    "    # load imdb with datasets\n",
    "    ds = load_dataset(dataset_name, split=\"train\")\n",
    "    ds = ds.rename_columns({\"text\": \"review\"})\n",
    "    ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n",
    "\n",
    "    input_size = LengthSampler(input_min_text_length, input_max_text_length)\n",
    "\n",
    "    def tokenize(sample):\n",
    "        sample[\"input_ids\"] = tokenizer.encode(sample[\"review\"])[: input_size()]\n",
    "        sample[\"query\"] = tokenizer.decode(sample[\"input_ids\"])\n",
    "        return sample\n",
    "\n",
    "    ds = ds.map(tokenize, batched=False)\n",
    "    ds.set_format(type=\"torch\")\n",
    "    return ds\n",
    "\n",
    "\n",
    "dataset = build_dataset(tokenizer, dataset_name='/mnt/nas1/dong-qichang/corpus/general/imdb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "L_q4qs35AxcR"
   },
   "outputs": [],
   "source": [
    "output_min_length = 4\n",
    "output_max_length = 16\n",
    "output_length_sampler = LengthSampler(output_min_length, output_max_length)\n",
    "\n",
    "#### get a batch from the dataset\n",
    "bs = 16\n",
    "output_data = dict()\n",
    "dataset.set_format(\"pandas\")\n",
    "df_batch = dataset[:].sample(bs)\n",
    "output_data[\"query\"] = df_batch[\"query\"].tolist()\n",
    "query_tensors = df_batch[\"input_ids\"].tolist()\n",
    "\n",
    "# :: [Resp]\n",
    "response_tensors_ref, response_tensors = [], []\n",
    "# :: [[Resp]]\n",
    "response_tensors_best_of = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4])\n",
      "torch.Size([4, 4])\n"
     ]
    }
   ],
   "source": [
    "query = torch.tensor(query_tensors[0])\n",
    "print(query.shape)\n",
    "queries = query.repeat((N_BEST_OF, 1))\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVfpyHnZBLKY"
   },
   "source": [
    "\n",
    "Generation using various models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-imZ7uEFBNbw"
   },
   "outputs": [],
   "source": [
    "gen_kwargs = {\"min_length\": -1, \"top_k\": 0.0, \"top_p\": 1.0, \"do_sample\": True, \"pad_token_id\": tokenizer.eos_token_id}\n",
    "sent_kwargs = {\"top_k\": None, \"function_to_apply\": \"none\", \"batch_size\": 16}\n",
    "\n",
    "for i in range(bs):\n",
    "    gen_len = output_length_sampler()\n",
    "\n",
    "    query = torch.tensor(query_tensors[i])\n",
    "\n",
    "    output = ref_model.generate(query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors_ref.append(tokenizer.decode(output))\n",
    "\n",
    "    output = model.generate(query.unsqueeze(dim=0).to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors.append(tokenizer.decode(output))\n",
    "\n",
    "    # generating copies of the same query for the Best-of-n sampling\n",
    "    queries = query.repeat((N_BEST_OF, 1))\n",
    "    output = ref_model.generate(queries.to(device), max_new_tokens=gen_len, **gen_kwargs).squeeze()\n",
    "    response_tensors_best_of.append(tokenizer.batch_decode(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp5FC0Y5h_Sf"
   },
   "source": [
    "Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PyDbbAQ0F_h7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'label': 'POSITIVE', 'score': 0.7179132103919983}, {'label': 'NEGATIVE', 'score': -0.6458280682563782}], [{'label': 'NEGATIVE', 'score': 2.1390843391418457}, {'label': 'POSITIVE', 'score': -2.585556983947754}], [{'label': 'NEGATIVE', 'score': 2.3338136672973633}, {'label': 'POSITIVE', 'score': -2.741856813430786}], [{'label': 'NEGATIVE', 'score': 1.3297553062438965}, {'label': 'POSITIVE', 'score': -1.7232002019882202}], [{'label': 'POSITIVE', 'score': 1.396438479423523}, {'label': 'NEGATIVE', 'score': -1.3023478984832764}], [{'label': 'NEGATIVE', 'score': 2.2352981567382812}, {'label': 'POSITIVE', 'score': -2.5556936264038086}], [{'label': 'POSITIVE', 'score': 2.4053659439086914}, {'label': 'NEGATIVE', 'score': -2.140338182449341}], [{'label': 'POSITIVE', 'score': 1.2411270141601562}, {'label': 'NEGATIVE', 'score': -1.061644196510315}], [{'label': 'NEGATIVE', 'score': 0.6906370520591736}, {'label': 'POSITIVE', 'score': -1.0696840286254883}], [{'label': 'NEGATIVE', 'score': 1.5734862089157104}, {'label': 'POSITIVE', 'score': -2.0335981845855713}], [{'label': 'POSITIVE', 'score': 1.5398967266082764}, {'label': 'NEGATIVE', 'score': -1.4001928567886353}], [{'label': 'POSITIVE', 'score': 0.8338059186935425}, {'label': 'NEGATIVE', 'score': -0.8139742016792297}], [{'label': 'NEGATIVE', 'score': 0.5790225863456726}, {'label': 'POSITIVE', 'score': -0.8603642582893372}], [{'label': 'NEGATIVE', 'score': 2.3426051139831543}, {'label': 'POSITIVE', 'score': -2.7489681243896484}], [{'label': 'POSITIVE', 'score': 0.30340659618377686}, {'label': 'NEGATIVE', 'score': -0.4057912230491638}], [{'label': 'NEGATIVE', 'score': 0.4795352518558502}, {'label': 'POSITIVE', 'score': -0.9848251342773438}]]\n"
     ]
    }
   ],
   "source": [
    "outputs = reward_pipe(response_tensors_ref, **sent_kwargs)\n",
    "print(outputs)\n",
    "\n",
    "scores_ref = [output[0][\"score\"] for output in reward_pipe(response_tensors_ref, **sent_kwargs)]\n",
    "scores = [output[0][\"score\"] for output in reward_pipe(response_tensors, **sent_kwargs)]\n",
    "scores_best_of = []\n",
    "for i, response in enumerate(response_tensors_best_of):\n",
    "    # base_score = scores_ref[i]\n",
    "    scores_best_of.append(torch.tensor([output[0][\"score\"] for output in reward_pipe(response, **sent_kwargs)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fidois a mofie and Freda, Major Hans Godel, Norma', 'A mercilessly corny and vicious homosexual movie', 'Really, really bad. I cannot rate this movie. Sort of. This was the lot, as', \"Using tons of stock footage, it seemed VW's editors had it\", 'Trash/bad) but was pretty good. Good scen', 'What a disappointment!<br /><br />Muse narration- Wow, Slimer showed clearly this is', 'The acting, other reviews notwithstanding, is good, especially by the moody Elijah Wood, who gives it a', 'Tobe Hooper has made his interest in the bullet subjects seemingly complex', \"This isn't a big deal considering the tour\", 'This is not a good chance for those who preclude exploring the', \"There's nothing more beautiful, but essential.<|endoftext|>\", 'I have previously seen Zu Fusilier and I', '...but I regret the mistake.<br /><br', 'This movie is a disgrace to the intelligence of so many, and I surmise that even', \"John Leguizemo) who's warning us about Romero's other films. The\", 'In an attempt to cash in on abroad, the investigation into']\n",
      "['Fidois a resemblance to Marx, and the very next day supporting it. The plot', 'A mercilessly corny and very good,', 'Really, really bad. The computer MLady is a very great director. She was also so amazing', 'Using tons of stock footage, which is a great film, but', 'Trash/bad humour/bad humour/bad humour/', 'What a disappointment!<br /><br />I loved it. It was the best of the tenth', \"The acting, other reviews notwithstanding, the BBC's confirmation that Indonesia has a very good shot of the world.\", 'Tobe Hooper has made a great movie, and with the colorful', \"This isn't telegenic, but it\", 'This is not a good creepy story. It is a great', \"There's nothing else to say. It's a very funny movie.\", 'I have previously seen ZuJux at first, and', \"...but I regret that mistake. It's a wonderful\", 'This movie is a disgrace to the morality of the so-called movie. It is a great', \"John Leguizemo has a lot of personality and wonderful camera. It's his\", 'In an attempt to cash in on the marketing of this film']\n",
      "[0.7179132103919983, 2.1390843391418457, 2.3338136672973633, 1.3297553062438965, 1.396438479423523, 2.2352981567382812, 2.4053659439086914, 1.2411270141601562, 0.6906370520591736, 1.5734862089157104, 1.5398967266082764, 0.8338059186935425, 0.5790225863456726, 2.3426051139831543, 0.30340659618377686, 0.4795352518558502]\n",
      "[1.6318426132202148, 1.8991962671279907, 1.7248280048370361, 0.005345379002392292, 2.1855404376983643, 1.688368320465088, 1.5067569017410278, 2.739001512527466, 0.12929818034172058, 2.1355490684509277, 2.5244414806365967, 1.0604758262634277, 2.4894893169403076, 0.7889848947525024, 2.731924057006836, 1.6605396270751953]\n",
      "22.141191571950912 26.901581888087094\n",
      "16 torch.Size([4])\n",
      "tensor([25.5174, 19.0372, 25.5036, 25.6218])\n",
      "torch.Size([64]) tensor(95.6799)\n"
     ]
    }
   ],
   "source": [
    "print(response_tensors_ref)\n",
    "print(response_tensors)\n",
    "print(scores_ref)\n",
    "print(scores)\n",
    "print(sum(scores_ref), sum(scores))\n",
    "print(len(scores_best_of), scores_best_of[0].shape)\n",
    "print(sum(scores_best_of))\n",
    "t = torch.concat(scores_best_of, dim=0)\n",
    "print(t.shape, sum(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 682
    },
    "id": "nA1GDNJEiGm-",
    "outputId": "1389c686-0751-4304-dea2-b71fd68748e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 4\n",
      "22.141191571950912 26.901581888087094 33.59040355682373\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>response (ref)</th>\n",
       "      <th>scores (ref)</th>\n",
       "      <th>response (RLHF)</th>\n",
       "      <th>scores (RLHF)</th>\n",
       "      <th>response (best_of)</th>\n",
       "      <th>scores (best_of)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fidois a</td>\n",
       "      <td>Fidois a mofie and Freda, Major Hans Godel, Norma</td>\n",
       "      <td>0.717913</td>\n",
       "      <td>Fidois a resemblance to Marx, and the very nex...</td>\n",
       "      <td>1.631843</td>\n",
       "      <td>Fidois a nice role, her role particularly cast...</td>\n",
       "      <td>2.323620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A mercilessly corny</td>\n",
       "      <td>A mercilessly corny and vicious homosexual movie</td>\n",
       "      <td>2.139084</td>\n",
       "      <td>A mercilessly corny and very good,</td>\n",
       "      <td>1.899196</td>\n",
       "      <td>A mercilessly corny insult to all the</td>\n",
       "      <td>2.318306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Really, really bad.</td>\n",
       "      <td>Really, really bad. I cannot rate this movie. ...</td>\n",
       "      <td>2.333814</td>\n",
       "      <td>Really, really bad. The computer MLady is a ve...</td>\n",
       "      <td>1.724828</td>\n",
       "      <td>Really, really bad. The movie was only good fo...</td>\n",
       "      <td>2.517596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Using tons of stock footage</td>\n",
       "      <td>Using tons of stock footage, it seemed VW's ed...</td>\n",
       "      <td>1.329755</td>\n",
       "      <td>Using tons of stock footage, which is a great ...</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>Using tons of stock footage of actual episodes...</td>\n",
       "      <td>2.060562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trash/bad</td>\n",
       "      <td>Trash/bad) but was pretty good. Good scen</td>\n",
       "      <td>1.396438</td>\n",
       "      <td>Trash/bad humour/bad humour/bad humour/</td>\n",
       "      <td>2.185540</td>\n",
       "      <td>Trash/bad timing/actors/hand-me</td>\n",
       "      <td>2.425057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What a disappointment!&lt;br /</td>\n",
       "      <td>What a disappointment!&lt;br /&gt;&lt;br /&gt;Muse narrati...</td>\n",
       "      <td>2.235298</td>\n",
       "      <td>What a disappointment!&lt;br /&gt;&lt;br /&gt;I loved it. ...</td>\n",
       "      <td>1.688368</td>\n",
       "      <td>What a disappointment!&lt;br /&gt;&lt;br /&gt;Empathy dial...</td>\n",
       "      <td>2.629115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The acting, other reviews notwithstanding,</td>\n",
       "      <td>The acting, other reviews notwithstanding, is ...</td>\n",
       "      <td>2.405366</td>\n",
       "      <td>The acting, other reviews notwithstanding, the...</td>\n",
       "      <td>1.506757</td>\n",
       "      <td>The acting, other reviews notwithstanding, pic...</td>\n",
       "      <td>2.447833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tobe Hooper has made</td>\n",
       "      <td>Tobe Hooper has made his interest in the bulle...</td>\n",
       "      <td>1.241127</td>\n",
       "      <td>Tobe Hooper has made a great movie, and with t...</td>\n",
       "      <td>2.739002</td>\n",
       "      <td>Tobe Hooper has made a magnificent portrait of...</td>\n",
       "      <td>2.764252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>This isn't</td>\n",
       "      <td>This isn't a big deal considering the tour</td>\n",
       "      <td>0.690637</td>\n",
       "      <td>This isn't telegenic, but it</td>\n",
       "      <td>0.129298</td>\n",
       "      <td>This isn't how they get their points across</td>\n",
       "      <td>1.088183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is not a good</td>\n",
       "      <td>This is not a good chance for those who preclu...</td>\n",
       "      <td>1.573486</td>\n",
       "      <td>This is not a good creepy story. It is a great</td>\n",
       "      <td>2.135549</td>\n",
       "      <td>This is not a good adaptation of James De Havi...</td>\n",
       "      <td>1.864987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>There's nothing</td>\n",
       "      <td>There's nothing more beautiful, but essential....</td>\n",
       "      <td>1.539897</td>\n",
       "      <td>There's nothing else to say. It's a very funny...</td>\n",
       "      <td>2.524441</td>\n",
       "      <td>There's nothing classic about this film and th...</td>\n",
       "      <td>2.117697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I have previously seen Zu</td>\n",
       "      <td>I have previously seen Zu Fusilier and I</td>\n",
       "      <td>0.833806</td>\n",
       "      <td>I have previously seen ZuJux at first, and</td>\n",
       "      <td>1.060476</td>\n",
       "      <td>I have previously seen Zuelle's live shows on BBC</td>\n",
       "      <td>1.317591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>...but I regret</td>\n",
       "      <td>...but I regret the mistake.&lt;br /&gt;&lt;br</td>\n",
       "      <td>0.579023</td>\n",
       "      <td>...but I regret that mistake. It's a wonderful</td>\n",
       "      <td>2.489489</td>\n",
       "      <td>...but I regret that the film was as interesti...</td>\n",
       "      <td>1.115591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>This movie is a disgrace to the</td>\n",
       "      <td>This movie is a disgrace to the intelligence o...</td>\n",
       "      <td>2.342605</td>\n",
       "      <td>This movie is a disgrace to the morality of th...</td>\n",
       "      <td>0.788985</td>\n",
       "      <td>This movie is a disgrace to the cinema. I kept...</td>\n",
       "      <td>2.595712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>John Leguizemo</td>\n",
       "      <td>John Leguizemo) who's warning us about Romero'...</td>\n",
       "      <td>0.303407</td>\n",
       "      <td>John Leguizemo has a lot of personality and wo...</td>\n",
       "      <td>2.731924</td>\n",
       "      <td>John Leguizemo puts an unnecessarily short pas...</td>\n",
       "      <td>2.466186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>In an attempt to cash in on</td>\n",
       "      <td>In an attempt to cash in on abroad, the invest...</td>\n",
       "      <td>0.479535</td>\n",
       "      <td>In an attempt to cash in on the marketing of t...</td>\n",
       "      <td>1.660540</td>\n",
       "      <td>In an attempt to cash in on some well deserved...</td>\n",
       "      <td>1.538115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         query  \\\n",
       "0                                     Fidois a   \n",
       "1                          A mercilessly corny   \n",
       "2                          Really, really bad.   \n",
       "3                  Using tons of stock footage   \n",
       "4                                    Trash/bad   \n",
       "5                  What a disappointment!<br /   \n",
       "6   The acting, other reviews notwithstanding,   \n",
       "7                         Tobe Hooper has made   \n",
       "8                                   This isn't   \n",
       "9                           This is not a good   \n",
       "10                             There's nothing   \n",
       "11                   I have previously seen Zu   \n",
       "12                             ...but I regret   \n",
       "13             This movie is a disgrace to the   \n",
       "14                              John Leguizemo   \n",
       "15                 In an attempt to cash in on   \n",
       "\n",
       "                                       response (ref)  scores (ref)  \\\n",
       "0   Fidois a mofie and Freda, Major Hans Godel, Norma      0.717913   \n",
       "1    A mercilessly corny and vicious homosexual movie      2.139084   \n",
       "2   Really, really bad. I cannot rate this movie. ...      2.333814   \n",
       "3   Using tons of stock footage, it seemed VW's ed...      1.329755   \n",
       "4           Trash/bad) but was pretty good. Good scen      1.396438   \n",
       "5   What a disappointment!<br /><br />Muse narrati...      2.235298   \n",
       "6   The acting, other reviews notwithstanding, is ...      2.405366   \n",
       "7   Tobe Hooper has made his interest in the bulle...      1.241127   \n",
       "8          This isn't a big deal considering the tour      0.690637   \n",
       "9   This is not a good chance for those who preclu...      1.573486   \n",
       "10  There's nothing more beautiful, but essential....      1.539897   \n",
       "11           I have previously seen Zu Fusilier and I      0.833806   \n",
       "12              ...but I regret the mistake.<br /><br      0.579023   \n",
       "13  This movie is a disgrace to the intelligence o...      2.342605   \n",
       "14  John Leguizemo) who's warning us about Romero'...      0.303407   \n",
       "15  In an attempt to cash in on abroad, the invest...      0.479535   \n",
       "\n",
       "                                      response (RLHF)  scores (RLHF)  \\\n",
       "0   Fidois a resemblance to Marx, and the very nex...       1.631843   \n",
       "1                  A mercilessly corny and very good,       1.899196   \n",
       "2   Really, really bad. The computer MLady is a ve...       1.724828   \n",
       "3   Using tons of stock footage, which is a great ...       0.005345   \n",
       "4             Trash/bad humour/bad humour/bad humour/       2.185540   \n",
       "5   What a disappointment!<br /><br />I loved it. ...       1.688368   \n",
       "6   The acting, other reviews notwithstanding, the...       1.506757   \n",
       "7   Tobe Hooper has made a great movie, and with t...       2.739002   \n",
       "8                        This isn't telegenic, but it       0.129298   \n",
       "9      This is not a good creepy story. It is a great       2.135549   \n",
       "10  There's nothing else to say. It's a very funny...       2.524441   \n",
       "11         I have previously seen ZuJux at first, and       1.060476   \n",
       "12     ...but I regret that mistake. It's a wonderful       2.489489   \n",
       "13  This movie is a disgrace to the morality of th...       0.788985   \n",
       "14  John Leguizemo has a lot of personality and wo...       2.731924   \n",
       "15  In an attempt to cash in on the marketing of t...       1.660540   \n",
       "\n",
       "                                   response (best_of)  scores (best_of)  \n",
       "0   Fidois a nice role, her role particularly cast...          2.323620  \n",
       "1               A mercilessly corny insult to all the          2.318306  \n",
       "2   Really, really bad. The movie was only good fo...          2.517596  \n",
       "3   Using tons of stock footage of actual episodes...          2.060562  \n",
       "4                     Trash/bad timing/actors/hand-me          2.425057  \n",
       "5   What a disappointment!<br /><br />Empathy dial...          2.629115  \n",
       "6   The acting, other reviews notwithstanding, pic...          2.447833  \n",
       "7   Tobe Hooper has made a magnificent portrait of...          2.764252  \n",
       "8         This isn't how they get their points across          1.088183  \n",
       "9   This is not a good adaptation of James De Havi...          1.864987  \n",
       "10  There's nothing classic about this film and th...          2.117697  \n",
       "11  I have previously seen Zuelle's live shows on BBC          1.317591  \n",
       "12  ...but I regret that the film was as interesti...          1.115591  \n",
       "13  This movie is a disgrace to the cinema. I kept...          2.595712  \n",
       "14  John Leguizemo puts an unnecessarily short pas...          2.466186  \n",
       "15  In an attempt to cash in on some well deserved...          1.538115  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[\"response (ref)\"] = response_tensors_ref\n",
    "output_data[\"scores (ref)\"] = scores_ref\n",
    "output_data[\"response (RLHF)\"] = response_tensors\n",
    "output_data[\"scores (RLHF)\"] = scores\n",
    "print(len(scores_best_of), len(scores_best_of[0]))\n",
    "output_data[\"response (best_of)\"] = [\n",
    "    response_tensors_best_of[i][a.argmax().item()] for i, a in enumerate(scores_best_of)\n",
    "]\n",
    "output_data[\"scores (best_of)\"] = [a.max().item() for a in scores_best_of]\n",
    "\n",
    "\n",
    "# store results in a dataframe\n",
    "df_results = pd.DataFrame(output_data)\n",
    "print(df_results['scores (ref)'].sum(), df_results['scores (RLHF)'].sum(), df_results['scores (best_of)'].sum())\n",
    "df_results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
